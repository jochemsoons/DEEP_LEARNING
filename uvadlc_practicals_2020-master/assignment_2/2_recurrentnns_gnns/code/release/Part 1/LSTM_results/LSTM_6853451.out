Namespace(batch_size=256, dataset='bipalindrome', device='cuda:0', gpu_mem_frac=0.5, input_dim=1, input_length=20, learning_rate=0.0001, log_device_placement=False, max_norm=10.0, model_type='LSTM', num_classes=1, num_hidden=256, summary_path='./summaries/', train_steps=3000)
cuda:0
Load binary palindrome dataset ...
input length: 20
input length: 81
Initializing LSTM model ...
seq length: 81
input dim: 1
hidden dim: 256
num classes: 2
batch_size: 256
device: cuda:0


torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([256, 2])
torch.Size([256, 2])
torch.Size([2])
BIAS
torch.Size([2])
W_gx True
W_gh True
b_g True
W_ix True
W_ih True
b_i True
W_fx True
W_fh True
b_f True
W_ox True
W_oh True
b_o True
W_ph True
b_p True
embedding.weight False
[2020-11-20 13:29] Train Step 0000/3000, Batch Size = 256,                    Examples/Sec = 435.57, Accuracy = 0.46, Loss = 1.568
[2020-11-20 13:29] Train Step 0060/3000, Batch Size = 256,                    Examples/Sec = 1536.07, Accuracy = 0.63, Loss = 0.644
[2020-11-20 13:30] Train Step 0120/3000, Batch Size = 256,                    Examples/Sec = 1519.12, Accuracy = 0.69, Loss = 0.614
[2020-11-20 13:30] Train Step 0180/3000, Batch Size = 256,                    Examples/Sec = 1628.92, Accuracy = 0.60, Loss = 0.647
[2020-11-20 13:30] Train Step 0240/3000, Batch Size = 256,                    Examples/Sec = 2055.49, Accuracy = 0.65, Loss = 0.617
[2020-11-20 13:30] Train Step 0300/3000, Batch Size = 256,                    Examples/Sec = 1993.72, Accuracy = 0.65, Loss = 0.611
[2020-11-20 13:30] Train Step 0360/3000, Batch Size = 256,                    Examples/Sec = 1510.20, Accuracy = 0.67, Loss = 0.621
[2020-11-20 13:30] Train Step 0420/3000, Batch Size = 256,                    Examples/Sec = 1512.36, Accuracy = 0.67, Loss = 0.596
[2020-11-20 13:31] Train Step 0480/3000, Batch Size = 256,                    Examples/Sec = 1555.34, Accuracy = 0.67, Loss = 0.642
[2020-11-20 13:31] Train Step 0540/3000, Batch Size = 256,                    Examples/Sec = 1666.10, Accuracy = 0.67, Loss = 0.614
[2020-11-20 13:31] Train Step 0600/3000, Batch Size = 256,                    Examples/Sec = 1312.81, Accuracy = 0.66, Loss = 0.622
[2020-11-20 13:31] Train Step 0660/3000, Batch Size = 256,                    Examples/Sec = 1298.48, Accuracy = 0.71, Loss = 0.586
[2020-11-20 13:31] Train Step 0720/3000, Batch Size = 256,                    Examples/Sec = 1536.30, Accuracy = 0.69, Loss = 0.586
[2020-11-20 13:31] Train Step 0780/3000, Batch Size = 256,                    Examples/Sec = 2086.35, Accuracy = 0.68, Loss = 0.624
[2020-11-20 13:32] Train Step 0840/3000, Batch Size = 256,                    Examples/Sec = 1895.37, Accuracy = 0.70, Loss = 0.582
[2020-11-20 13:32] Train Step 0900/3000, Batch Size = 256,                    Examples/Sec = 1820.68, Accuracy = 0.64, Loss = 0.639
[2020-11-20 13:32] Train Step 0960/3000, Batch Size = 256,                    Examples/Sec = 1317.44, Accuracy = 0.68, Loss = 0.609
[2020-11-20 13:32] Train Step 1020/3000, Batch Size = 256,                    Examples/Sec = 1973.57, Accuracy = 0.65, Loss = 0.624
[2020-11-20 13:32] Train Step 1080/3000, Batch Size = 256,                    Examples/Sec = 1250.81, Accuracy = 0.63, Loss = 0.640
[2020-11-20 13:32] Train Step 1140/3000, Batch Size = 256,                    Examples/Sec = 1506.57, Accuracy = 0.64, Loss = 0.638
[2020-11-20 13:33] Train Step 1200/3000, Batch Size = 256,                    Examples/Sec = 1529.04, Accuracy = 0.65, Loss = 0.611
[2020-11-20 13:33] Train Step 1260/3000, Batch Size = 256,                    Examples/Sec = 1319.75, Accuracy = 0.70, Loss = 0.607
[2020-11-20 13:33] Train Step 1320/3000, Batch Size = 256,                    Examples/Sec = 1497.37, Accuracy = 0.66, Loss = 0.598
[2020-11-20 13:33] Train Step 1380/3000, Batch Size = 256,                    Examples/Sec = 1974.97, Accuracy = 0.70, Loss = 0.573
[2020-11-20 13:33] Train Step 1440/3000, Batch Size = 256,                    Examples/Sec = 1537.99, Accuracy = 0.71, Loss = 0.575
[2020-11-20 13:33] Train Step 1500/3000, Batch Size = 256,                    Examples/Sec = 1519.74, Accuracy = 0.71, Loss = 0.542
[2020-11-20 13:34] Train Step 1560/3000, Batch Size = 256,                    Examples/Sec = 1626.77, Accuracy = 0.66, Loss = 0.641
[2020-11-20 13:34] Train Step 1620/3000, Batch Size = 256,                    Examples/Sec = 1296.30, Accuracy = 0.67, Loss = 0.591
[2020-11-20 13:34] Train Step 1680/3000, Batch Size = 256,                    Examples/Sec = 1869.54, Accuracy = 0.69, Loss = 0.601
[2020-11-20 13:34] Train Step 1740/3000, Batch Size = 256,                    Examples/Sec = 1911.12, Accuracy = 0.66, Loss = 0.616
[2020-11-20 13:34] Train Step 1800/3000, Batch Size = 256,                    Examples/Sec = 1526.33, Accuracy = 0.63, Loss = 0.655
[2020-11-20 13:34] Train Step 1860/3000, Batch Size = 256,                    Examples/Sec = 1589.25, Accuracy = 0.71, Loss = 0.605
[2020-11-20 13:35] Train Step 1920/3000, Batch Size = 256,                    Examples/Sec = 1291.64, Accuracy = 0.67, Loss = 0.619
[2020-11-20 13:35] Train Step 1980/3000, Batch Size = 256,                    Examples/Sec = 1346.41, Accuracy = 0.67, Loss = 0.627
[2020-11-20 13:35] Train Step 2040/3000, Batch Size = 256,                    Examples/Sec = 1992.16, Accuracy = 0.63, Loss = 0.639
[2020-11-20 13:35] Train Step 2100/3000, Batch Size = 256,                    Examples/Sec = 1329.41, Accuracy = 0.73, Loss = 0.580
[2020-11-20 13:35] Train Step 2160/3000, Batch Size = 256,                    Examples/Sec = 1867.00, Accuracy = 0.64, Loss = 0.626
[2020-11-20 13:35] Train Step 2220/3000, Batch Size = 256,                    Examples/Sec = 1518.76, Accuracy = 0.68, Loss = 0.609
[2020-11-20 13:36] Train Step 2280/3000, Batch Size = 256,                    Examples/Sec = 1538.13, Accuracy = 0.70, Loss = 0.572
[2020-11-20 13:36] Train Step 2340/3000, Batch Size = 256,                    Examples/Sec = 1346.82, Accuracy = 0.63, Loss = 0.645
[2020-11-20 13:36] Train Step 2400/3000, Batch Size = 256,                    Examples/Sec = 1298.23, Accuracy = 0.68, Loss = 0.609
[2020-11-20 13:36] Train Step 2460/3000, Batch Size = 256,                    Examples/Sec = 1630.97, Accuracy = 0.64, Loss = 0.648
[2020-11-20 13:36] Train Step 2520/3000, Batch Size = 256,                    Examples/Sec = 1520.34, Accuracy = 0.64, Loss = 0.632
[2020-11-20 13:36] Train Step 2580/3000, Batch Size = 256,                    Examples/Sec = 1253.74, Accuracy = 0.66, Loss = 0.598
[2020-11-20 13:37] Train Step 2640/3000, Batch Size = 256,                    Examples/Sec = 1508.31, Accuracy = 0.66, Loss = 0.641
