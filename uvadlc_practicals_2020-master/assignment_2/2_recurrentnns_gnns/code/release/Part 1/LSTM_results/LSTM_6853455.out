Namespace(batch_size=256, dataset='bipalindrome', device='cuda:0', gpu_mem_frac=0.5, input_dim=1, input_length=20, learning_rate=0.0001, log_device_placement=False, max_norm=10.0, model_type='LSTM', num_classes=1, num_hidden=256, summary_path='./summaries/', train_steps=3000)
cuda:0
Load binary palindrome dataset ...
input length: 20
input length: 81
Initializing LSTM model ...
seq length: 81
input dim: 1
hidden dim: 256
num classes: 2
batch_size: 256
device: cuda:0


torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([162, 256])
torch.Size([162, 256])
torch.Size([256, 256])
torch.Size([256, 256])
torch.Size([256])
BIAS
torch.Size([256])
torch.Size([256, 2])
torch.Size([256, 2])
torch.Size([2])
BIAS
torch.Size([2])
W_gx True
W_gh True
b_g True
W_ix True
W_ih True
b_i True
W_fx True
W_fh True
b_f True
W_ox True
W_oh True
b_o True
W_ph True
b_p True
embedding.weight False
[2020-11-20 13:32] Train Step 0000/3000, Batch Size = 256,                    Examples/Sec = 433.57, Accuracy = 0.48, Loss = 2.434
[2020-11-20 13:32] Train Step 0060/3000, Batch Size = 256,                    Examples/Sec = 1748.06, Accuracy = 0.63, Loss = 0.637
[2020-11-20 13:32] Train Step 0120/3000, Batch Size = 256,                    Examples/Sec = 1695.99, Accuracy = 0.69, Loss = 0.599
[2020-11-20 13:33] Train Step 0180/3000, Batch Size = 256,                    Examples/Sec = 1354.62, Accuracy = 0.60, Loss = 0.642
[2020-11-20 13:33] Train Step 0240/3000, Batch Size = 256,                    Examples/Sec = 1673.59, Accuracy = 0.66, Loss = 0.610
[2020-11-20 13:33] Train Step 0300/3000, Batch Size = 256,                    Examples/Sec = 1297.26, Accuracy = 0.67, Loss = 0.610
[2020-11-20 13:33] Train Step 0360/3000, Batch Size = 256,                    Examples/Sec = 1527.13, Accuracy = 0.66, Loss = 0.618
[2020-11-20 13:33] Train Step 0420/3000, Batch Size = 256,                    Examples/Sec = 1742.23, Accuracy = 0.68, Loss = 0.596
[2020-11-20 13:33] Train Step 0480/3000, Batch Size = 256,                    Examples/Sec = 1752.79, Accuracy = 0.66, Loss = 0.651
[2020-11-20 13:34] Train Step 0540/3000, Batch Size = 256,                    Examples/Sec = 1542.17, Accuracy = 0.67, Loss = 0.614
[2020-11-20 13:34] Train Step 0600/3000, Batch Size = 256,                    Examples/Sec = 1576.33, Accuracy = 0.67, Loss = 0.617
[2020-11-20 13:34] Train Step 0660/3000, Batch Size = 256,                    Examples/Sec = 2024.66, Accuracy = 0.70, Loss = 0.582
[2020-11-20 13:34] Train Step 0720/3000, Batch Size = 256,                    Examples/Sec = 2003.94, Accuracy = 0.70, Loss = 0.577
[2020-11-20 13:34] Train Step 0780/3000, Batch Size = 256,                    Examples/Sec = 1317.69, Accuracy = 0.68, Loss = 0.632
[2020-11-20 13:34] Train Step 0840/3000, Batch Size = 256,                    Examples/Sec = 2119.93, Accuracy = 0.70, Loss = 0.585
[2020-11-20 13:35] Train Step 0900/3000, Batch Size = 256,                    Examples/Sec = 2024.09, Accuracy = 0.62, Loss = 0.668
[2020-11-20 13:35] Train Step 0960/3000, Batch Size = 256,                    Examples/Sec = 1971.87, Accuracy = 0.67, Loss = 0.618
[2020-11-20 13:35] Train Step 1020/3000, Batch Size = 256,                    Examples/Sec = 2024.64, Accuracy = 0.64, Loss = 0.623
[2020-11-20 13:35] Train Step 1080/3000, Batch Size = 256,                    Examples/Sec = 1301.01, Accuracy = 0.62, Loss = 0.656
[2020-11-20 13:35] Train Step 1140/3000, Batch Size = 256,                    Examples/Sec = 2034.80, Accuracy = 0.64, Loss = 0.640
[2020-11-20 13:35] Train Step 1200/3000, Batch Size = 256,                    Examples/Sec = 1334.64, Accuracy = 0.66, Loss = 0.621
[2020-11-20 13:35] Train Step 1260/3000, Batch Size = 256,                    Examples/Sec = 2024.14, Accuracy = 0.70, Loss = 0.613
[2020-11-20 13:36] Train Step 1320/3000, Batch Size = 256,                    Examples/Sec = 2093.97, Accuracy = 0.65, Loss = 0.606
[2020-11-20 13:36] Train Step 1380/3000, Batch Size = 256,                    Examples/Sec = 1681.96, Accuracy = 0.68, Loss = 0.576
[2020-11-20 13:36] Train Step 1440/3000, Batch Size = 256,                    Examples/Sec = 1777.46, Accuracy = 0.71, Loss = 0.584
[2020-11-20 13:36] Train Step 1500/3000, Batch Size = 256,                    Examples/Sec = 1288.62, Accuracy = 0.70, Loss = 0.552
[2020-11-20 13:36] Train Step 1560/3000, Batch Size = 256,                    Examples/Sec = 1626.91, Accuracy = 0.64, Loss = 0.642
[2020-11-20 13:36] Train Step 1620/3000, Batch Size = 256,                    Examples/Sec = 1536.52, Accuracy = 0.68, Loss = 0.586
[2020-11-20 13:37] Train Step 1680/3000, Batch Size = 256,                    Examples/Sec = 1932.05, Accuracy = 0.69, Loss = 0.597
[2020-11-20 13:37] Train Step 1740/3000, Batch Size = 256,                    Examples/Sec = 1352.16, Accuracy = 0.66, Loss = 0.619
[2020-11-20 13:37] Train Step 1800/3000, Batch Size = 256,                    Examples/Sec = 1568.96, Accuracy = 0.61, Loss = 0.655
[2020-11-20 13:37] Train Step 1860/3000, Batch Size = 256,                    Examples/Sec = 1938.24, Accuracy = 0.70, Loss = 0.619
[2020-11-20 13:37] Train Step 1920/3000, Batch Size = 256,                    Examples/Sec = 1300.67, Accuracy = 0.67, Loss = 0.613
